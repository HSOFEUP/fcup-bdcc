{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">BDCC project 1</h1>\n",
    "\n",
    "<h4 align=\"center\">By: Ant√≥nio Almeida, Miguel Ramalho</h4>\n",
    "\n",
    "<h5 align=\"center\"><a href=\"http://www.dcc.fc.up.pt/~edrdo/aulas/bdcc\">Big Data and Cloud Computing</a>, DCC/FCUP</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code necessary to run from the command line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    # This block is required to run the program from the command line in interface with a single Spark instance\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"BDCCp1\").master(\"local[*]\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided code - auxilliary functions\n",
    "\n",
    "__You should not need to edit these.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loadMovieLensData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(file, debug=False):\n",
    "    if debug: print('Reading ' + file)\n",
    "    return spark.read.csv(file, inferSchema=True, header=True)\n",
    "\n",
    "def readParquet(file, debug=False): \n",
    "    if debug: print('Reading ' + file)\n",
    "    return spark.read.parquet(file)\n",
    "\n",
    "def loadMovieLensData(path, format='parquet', debug=False):\n",
    "    if format == 'parquet':\n",
    "        movies = readParquet(path +'/movies.parquet', debug)\n",
    "        ratings = readParquet(path +'/ratings.parquet', debug)\n",
    "        tags = readParquet(path +'/tags.parquet', debug)\n",
    "    else:\n",
    "        movies = readCSV(path +'/movies.csv', debug)\n",
    "        ratings = readCSV(path +'/ratings.csv', debug)\n",
    "        tags = readCSV(path +'/tags.csv', debug)\n",
    "    \n",
    "    tags = tags.withColumn('tagl', F.explode(F.split(F.lower(F.col('tag')),'[ \\*\\+\\&\\/\\%\\-\\$\\#\\'\\)\\(\\[\\[\\],.!?;:\\t\\n\"]+')))\\\n",
    "            .drop('tag')\\\n",
    "            .withColumnRenamed('tagl','tag')\n",
    "    if (debug):\n",
    "        print('> movies')\n",
    "        movies.printSchema()\n",
    "        movies.show()\n",
    "        \n",
    "        print('> ratings')\n",
    "        ratings.printSchema()\n",
    "        ratings.show()\n",
    "        \n",
    "        print('> tags')\n",
    "        tags.printSchema()\n",
    "        tags.show()\n",
    "    return (movies, ratings, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writeCSV / writeParquet (use them to write a data frame to CSV or Parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCSV(df, path): \n",
    "    df.write.csv(path, header=True, mode='overwrite')\n",
    "\n",
    "def writeParquet(df,path):\n",
    "    df.write.parquet(path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### createTagListDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTagListDF(csvTagList):\n",
    "    # receives a string of space-separated tags and returns them in a dataframe\n",
    "    return spark.createDataFrame([ (t,) for t in csvTagList.split(' ')], ['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of functions available only in Spark 2.4 (GCP Spark instances run Spark 2.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType,IntegerType\n",
    "\n",
    "# Define F.array_intersect if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_intersect'):\n",
    "    F.array_intersect = spark.udf.register('array_intersect', \n",
    "        lambda x,y: list(set(x) & set(y)), ArrayType(IntegerType()))\n",
    "\n",
    "# Define F.array_union if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_union'):\n",
    "    F.array_union = spark.udf.register('array_union', \n",
    "        lambda x,y: list(set(x) | set(y)), ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group code - auxilliary functions\n",
    "\n",
    "These come before the functions to define due to jupyter top-down logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(*, data, w='w', d='d', n=None, debug=False):\n",
    "    \"\"\"Calculates the Inverse Document Frequency (IDF) of a DataFrame\n",
    "\n",
    "    By default, uses the standard usage of IDF, i.e., 'w'\n",
    "    is a word in a document 'd'. If 'n' is set, it also \n",
    "    returns a column containing the number of documents\n",
    "    in which word 'w' appears.\n",
    "\n",
    "    Args:\n",
    "        data: A DataFrame instance.\n",
    "        w: Column name for 'words'\n",
    "        d: Column name for 'documents'\n",
    "        n: Name for the output column containing the\n",
    "            number of documents in which 'w' appears\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with 'w', 'IDF, [n] as columns\n",
    "    \"\"\"\n",
    "    n_w_D = data\\\n",
    "           .groupBy(w)\\\n",
    "           .agg(F.countDistinct(d).alias('n_w_D'))\n",
    "    if debug: n_w_D.orderBy('n_w_D',ascending=False).show()\n",
    "        \n",
    "    size_of_D = data.select(d).distinct().count()\n",
    "    if debug: print(\"|D| = %d\" % size_of_D)\n",
    "    \n",
    "    IDF = n_w_D.withColumn('IDF', F.log2(size_of_D / F.col('n_W_D')))\n",
    "\n",
    "    if n: IDF = IDF.withColumnRenamed('n_w_D', n)\n",
    "    else: IDF = IDF.drop('n_w_D')\n",
    "    return IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to define \n",
    "\n",
    "__This is the section that will be evaluated.__\n",
    "\n",
    "__Include your code for the various functions required in the assigment below.__\n",
    "\n",
    "__You may include other auxilliary functions required for computation here\n",
    "but NOT test code (see below).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some auxiliary functions required for computation are in the [section above](#Group-code---auxilliary-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfTags\n",
    "Calculates the TF-IDF metric for tags in association to movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfTags(tags, debug=False):\n",
    "    # f is the the number of times tag has been used in with movieId\n",
    "    # aggregate as (tag, movieId, f)\n",
    "    df_f = tags.groupBy('tag', 'movieId')\\\n",
    "               .agg(F.count('userId').alias('f'))\n",
    "    \n",
    "    # f_max is the maximum absolute frequency of any tag used for movieId\n",
    "    # aggregate as (movieId, f_max)\n",
    "    df_f_max = df_f.groupBy('movieId')\\\n",
    "                   .agg(F.max('f').alias('f_max'))\n",
    "    \n",
    "    # call external function to calculate IDF\n",
    "    df_idf = get_idf(data=tags, w='tag', d='movieId', n='n', debug=debug)\n",
    "    \n",
    "    # join f_max on movieId, calculate TF, join with IDF on tag\n",
    "    df = df_f.join(df_f_max, 'movieId')\\\n",
    "             .withColumn('TF', F.col('f') / F.col('f_max'))\\\n",
    "             .join(df_idf, 'tag')\n",
    "    \n",
    "    # return dataframe with TF_IDF\n",
    "    return df.withColumn('TF_IDF', df.TF * df.IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTag\n",
    "Recomends movies that have the highest TF-IDF value for a given (single) tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendByTag(singleTag, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    # start by most complexity-reducing operation: filter\n",
    "    # join to get movie title\n",
    "    # order by descending TFIDF + ascending lexicographic title\n",
    "    # remove unnecessary columns\n",
    "    # return results limited to numberOfResults\n",
    "    df = TFIDF_tags.filter(TFIDF_tags.tag == singleTag)\\\n",
    "                   .filter(TFIDF_tags.f_max >= min_fmax)\\\n",
    "                   .join(movies, 'movieId')\\\n",
    "                   .orderBy(['TF_IDF','title'], ascending=[0,1])\\\n",
    "                   .select('movieId', 'title', 'TF_IDF')\\\n",
    "                   .limit(numberOfResults)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTags\n",
    "Recomends movies that have the highest combined (sum of) TF-IDF value for several given tags (1 or more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendByTags(searchTags, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    df_search_tags = createTagListDF(searchTags)\n",
    "    if debug:\n",
    "        print('> Search tags DF: ' + searchTags)\n",
    "        df_search_tags.show()\n",
    "    # filter by min_fmax\n",
    "    # join df_search_tags to remove unasked tags\n",
    "    # group by movieId and aggregate on the SUM of tfidf\n",
    "    # join movies to get title\n",
    "    # order by descending SUM_TF_IDF + ascending lexicographic title\n",
    "    # force column order in the examples\n",
    "    # return results limited to numberOfResults\n",
    "    return TFIDF_tags.filter(TFIDF_tags.f_max >= min_fmax)\\\n",
    "                     .join(df_search_tags, 'tag', 'inner')\\\n",
    "                     .groupBy('movieId')\\\n",
    "                     .agg(F.sum('TF_IDF').alias('SUM_TF_IDF'))\\\n",
    "                     .join(movies, 'movieId')\\\n",
    "                     .orderBy(['SUM_TF_IDF', 'title'], ascending=[0,1])\\\n",
    "                     .select([\"movieId\", \"title\", \"SUM_TF_IDF\"])\\\n",
    "                     .limit(numberOfResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jiMovieSimilarity\n",
    "Calculates the Jaccard index to measure similarity between movies based on user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jiMovieSimilarity(ratings, minRatings=10, debug=False):\n",
    "  # TODO\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendBySimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendBySimilarity(movieId, movies, jiForMovies, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input data set and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gs://bdcc1819/p1/data/tiny3/movies.csv\n",
      "Reading gs://bdcc1819/p1/data/tiny3/ratings.csv\n",
      "Reading gs://bdcc1819/p1/data/tiny3/tags.csv\n",
      "> movies\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|      Jumanji (1995)|\n",
      "|      3|Grumpier Old Men ...|\n",
      "|      4|Waiting to Exhale...|\n",
      "|      5|Father of the Bri...|\n",
      "|      6|         Heat (1995)|\n",
      "|      7|      Sabrina (1995)|\n",
      "|      8| Tom and Huck (1995)|\n",
      "|      9| Sudden Death (1995)|\n",
      "|     10|    GoldenEye (1995)|\n",
      "|     11|American Presiden...|\n",
      "|     12|Dracula: Dead and...|\n",
      "|     13|        Balto (1995)|\n",
      "|     14|        Nixon (1995)|\n",
      "|     15|Cutthroat Island ...|\n",
      "|     16|       Casino (1995)|\n",
      "|     17|Sense and Sensibi...|\n",
      "|     18|   Four Rooms (1995)|\n",
      "|     19|Ace Ventura: When...|\n",
      "|     20|  Money Train (1995)|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> ratings\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+-------+------+------+\n",
      "|movieId|userId|rating|\n",
      "+-------+------+------+\n",
      "|      1|     1|   4.0|\n",
      "|      3|     1|   4.0|\n",
      "|      6|     1|   4.0|\n",
      "|     47|     1|   5.0|\n",
      "|     50|     1|   5.0|\n",
      "|     70|     1|   3.0|\n",
      "|    101|     1|   5.0|\n",
      "|    110|     1|   4.0|\n",
      "|    151|     1|   5.0|\n",
      "|     31|     3|   0.5|\n",
      "|     21|     4|   3.0|\n",
      "|     32|     4|   2.0|\n",
      "|     45|     4|   3.0|\n",
      "|     47|     4|   2.0|\n",
      "|     52|     4|   3.0|\n",
      "|     58|     4|   3.0|\n",
      "|    106|     4|   4.0|\n",
      "|    125|     4|   5.0|\n",
      "|    126|     4|   1.0|\n",
      "|      1|     5|   4.0|\n",
      "+-------+------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> tags\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n",
      "+-------+------+--------------+\n",
      "|movieId|userId|           tag|\n",
      "+-------+------+--------------+\n",
      "|      2|    62|       fantasy|\n",
      "|      2|    62|         magic|\n",
      "|      2|    62|         board|\n",
      "|      2|    62|          game|\n",
      "|      2|    62|         robin|\n",
      "|      2|    62|      williams|\n",
      "|    110|    62|     beautiful|\n",
      "|    110|    62|       scenery|\n",
      "|    110|    62|          epic|\n",
      "|    110|    62|    historical|\n",
      "|    110|    62| inspirational|\n",
      "|    110|    62|      medieval|\n",
      "|    110|    62|           mel|\n",
      "|    110|    62|        gibson|\n",
      "|    110|    62|         oscar|\n",
      "|    110|    62|          best|\n",
      "|    110|    62|cinematography|\n",
      "|    110|    62|              |\n",
      "|    110|    62|       revenge|\n",
      "|    110|    62|         sword|\n",
      "+-------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "bucket = 'gs://bdcc1819'\n",
    "path = '/p1/data/'\n",
    "dataset = 'tiny3'\n",
    "fullPath = bucket + path + dataset\n",
    "\n",
    "movies, ratings, tags = loadMovieLensData(fullPath, format='csv', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test code \n",
    "\n",
    "__Include test code below that you may need here.__\n",
    "\n",
    "__The initial contents are only meant as an example.__\n",
    "\n",
    "__This section will NOT be evaluated.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---+-----+------------------+---+-----------------+-----------------+\n",
      "|        tag|movieId|  f|f_max|                TF|  n|              IDF|           TF_IDF|\n",
      "+-----------+-------+---+-----+------------------+---+-----------------+-----------------+\n",
      "|       time|     32|  3|    3|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|     travel|     32|  3|    3|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|      pixar|      1|  2|    2|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|       game|      2|  2|    2|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|apocalyptic|     32|  2|    3|0.6666666666666666|  1|5.426264754702098|3.617509836468065|\n",
      "|       post|     32|  2|    3|0.6666666666666666|  1|5.426264754702098|3.617509836468065|\n",
      "|      moldy|      3|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|        old|      3|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|  pregnancy|      5|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|      mafia|     16|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|  hollywood|     21|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "| alcoholism|     25|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "| kidnapping|     29|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|       high|     31|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|     school|     31|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|    teacher|     31|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|     animal|     34|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|        for|     34|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|       good|     34|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "|      movie|     34|  1|    1|               1.0|  1|5.426264754702098|5.426264754702098|\n",
      "+-----------+-------+---+-----+------------------+---+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get TF-IDF for tags\n",
    "tfidf = tfidfTags(tags, debug=False)\n",
    "tfidf.cache()\n",
    "# guarantee all columns are present\n",
    "assert tfidf.columns == ['tag', 'movieId', 'f', 'f_max', 'TF', 'n', 'IDF', 'TF_IDF'],\\\n",
    "    \"Columns do not match expected values for tfidfTags\"\n",
    "# preview the dataframe\n",
    "tfidf.orderBy(['f','TF_IDF','movieId','tag'], ascending=[0,0,1,1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+\n",
      "|movieId|               title|           TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|     47|Seven (a.k.a. Se7...|3.841302253980942|\n",
      "|     50|Usual Suspects, T...|3.841302253980942|\n",
      "|     32|Twelve Monkeys (a...|1.280434084660314|\n",
      "+-------+--------------------+-----------------+\n",
      "\n",
      "+-------+--------------------+-----------------+\n",
      "|movieId|               title|           TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|     22|      Copycat (1995)|4.426264754702098|\n",
      "|     47|Seven (a.k.a. Se7...|4.426264754702098|\n",
      "+-------+--------------------+-----------------+\n",
      "\n",
      "+-------+--------------------+-----------------+\n",
      "|movieId|               title|           TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|      5|Father of the Bri...|3.841302253980942|\n",
      "|      7|      Sabrina (1995)|3.841302253980942|\n",
      "|     32|Twelve Monkeys (a...|1.280434084660314|\n",
      "+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommend by tag, tests for tiny3\n",
    "recommendByTag('twist', tfidf, movies, min_fmax=1).show()\n",
    "recommendByTag('killer', tfidf, movies, min_fmax=1).show()\n",
    "recommendByTag('remake', tfidf, movies, min_fmax=1).show()\n",
    "\n",
    "rm = recommendByTag('twist', tfidf, movies, min_fmax=1, numberOfResults=2)\n",
    "assert rm.count() == 2, \"numberOfResults should be 2\"\n",
    "assert rm.columns == [\"movieId\", \"title\", \"TF_IDF\"], \"unexpected columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+\n",
      "|movieId|               title|       SUM_TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|     39|     Clueless (1995)|7.682604507961884|\n",
      "|     28|   Persuasion (1995)|7.682604507961884|\n",
      "|     17|Sense and Sensibi...|7.682604507961884|\n",
      "+-------+--------------------+-----------------+\n",
      "\n",
      "+-------+--------------------+-----------------+\n",
      "|movieId|               title|       SUM_TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|     32|Twelve Monkeys (a...|7.987132924022726|\n",
      "|      5|Father of the Bri...|3.841302253980942|\n",
      "|      7|      Sabrina (1995)|3.841302253980942|\n",
      "|     47|Seven (a.k.a. Se7...|3.841302253980942|\n",
      "|     50|Usual Suspects, T...|3.841302253980942|\n",
      "+-------+--------------------+-----------------+\n",
      "\n",
      "+-------+--------------------+-----------------+\n",
      "|movieId|               title|       SUM_TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|      2|      Jumanji (1995)|5.426264754702098|\n",
      "|      5|Father of the Bri...|3.841302253980942|\n",
      "|      7|      Sabrina (1995)|3.841302253980942|\n",
      "|     32|Twelve Monkeys (a...|1.280434084660314|\n",
      "+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommend by tags, tests for tiny3\n",
    "recommendByTags('jane austen', tfidf, movies,min_fmax=1).show()\n",
    "recommendByTags('remake time twist', tfidf, movies, min_fmax=1).show()\n",
    "recommendByTags('robin williams remake', tfidf, movies, min_fmax=1).show()\n",
    "\n",
    "rm = recommendByTags('remake time twist', tfidf, movies, min_fmax=1, numberOfResults=4)\n",
    "assert rm.count() == 4, \"numberOfResults should be 4\"\n",
    "assert rm.columns == [\"movieId\", \"title\", \"SUM_TF_IDF\"], \"unexpected columns\"\n",
    "\n",
    "# Tests for tiny 1 (?)\n",
    "# recommendByTags('tom hanks airport', tfidf, movies, numberOfResults=20).show()\n",
    "# recommendByTags('tom hanks', tfidf, movies, numberOfResults=20).show()\n",
    "# recommendByTags('hitchcock birds', tfidf, movies, numberOfResults=10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiM = jiMovieSimilarity(ratings)\n",
    "\n",
    "#jiM.orderBy(['JI','m1','m2'], ascending=[0,1,1]).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jiM.cache()\n",
    "\n",
    "# Pulp Fiction\n",
    "#sm = recommendBySimilarity(296, movies, jiM)\n",
    "#sm.show()\n",
    "\n",
    "# Fight club\n",
    "#sm = recommendBySimilarity(2959, movies, jiM)\n",
    "#sm.show()\n",
    "    \n",
    "# Shrek\n",
    "#sm = recommendBySimilarity(4306, movies, jiM)\n",
    "#sm.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made by the teacher\n",
    "### TODO: Remove ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTF(data, debug=False):\n",
    "    f_wd = data\\\n",
    "       .groupBy('w','d')\\\n",
    "             .agg(F.count('w').alias('f_wd'))\n",
    "    if debug:\n",
    "        f_wd.orderBy('d','w').show()\n",
    "\n",
    "    f_wd_max = f_wd\\\n",
    "             .groupBy('d')\\\n",
    "             .agg(F.max('f_wd').alias('f_wd_max'))\n",
    "    if debug:\n",
    "        f_wd_max.orderBy('d').show()\n",
    "        \n",
    "    TF = f_wd.join(f_wd_max, 'd')\\\n",
    "             .withColumn('TF', F.col('f_wd') / F.col('f_wd_max'))\\\n",
    "             .drop('f_wd','f_wd_max')\n",
    "    return TF\n",
    "\n",
    "def getIDF(data, debug=False):\n",
    "    n_w_D = data\\\n",
    "           .groupBy('w')\\\n",
    "           .agg(F.countDistinct('d').alias('n_w_D'))\n",
    "    if debug:\n",
    "        n_w_D.orderBy('n_w_D',ascending=False).show()\n",
    "        \n",
    "    size_of_D = data.select('d').distinct().count()\n",
    "    if debug:\n",
    "        print(\"|D| = %d\" % size_of_D)\n",
    "    \n",
    "    IDF = n_w_D\\\n",
    "            .withColumn('IDF', F.log2(size_of_D / F.col('n_w_D')))\\\n",
    "            .drop('n_w_D')\n",
    "            \n",
    "    return IDF\n",
    "    \n",
    "def getTF_IDF(data, debug=False):\n",
    "    TF = getTF(data, debug)\n",
    "    if debug:\n",
    "        TF.orderBy(['d','TF'],ascending=[1,0]).show(TF.count())\n",
    "    \n",
    "    IDF = getIDF(data, debug)\n",
    "    if debug:\n",
    "        IDF.orderBy(['IDF','w'], ascending=[0,1]).show(IDF.count())\n",
    "\n",
    "    TF_IDF = TF\\\n",
    "      .join(IDF,'w')\\\n",
    "      .withColumn('TF_IDF',F.col('TF') * F.col('IDF'))\n",
    "        \n",
    "    if debug:\n",
    "        TF_IDF.orderBy(['d','TF_IDF','w'],ascending=[1,0,1]).show(TF_IDF.count())\n",
    "    return TF_IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}