{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDCC project 1 \n",
    "\n",
    "_[Big Data and Cloud Computing](http://www.dcc.fc.up.pt/~edrdo/aulas/bdcc), DCC/FCUP_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code necessary to run from the command line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    # This block is required to run the program from the command line\n",
    "    # in interface with a single Spark instance\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"BDCCp1\")\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided code - auxilliary functions\n",
    "\n",
    "__You should not need to edit these.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loadMovieLensData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def readCSV(file, debug=False):\n",
    "    if debug:\n",
    "      print('Reading ' + file)\n",
    "    return spark.read.csv(file, inferSchema=True, header=True)\n",
    "\n",
    "def readParquet(file, debug=False): \n",
    "    if debug:\n",
    "       print('Reading ' + file)\n",
    "    return spark.read.parquet(file)\n",
    "\n",
    "def loadMovieLensData(path, format='parquet', debug=False):\n",
    "    if format == 'parquet':\n",
    "       movies = readParquet(path +'/movies.parquet', debug)\n",
    "       ratings = readParquet(path +'/ratings.parquet', debug)\n",
    "       tags = readParquet(path +'/tags.parquet', debug)\n",
    "    else:\n",
    "       movies = readCSV(path +'/movies.csv', debug)\n",
    "       ratings = readCSV(path +'/ratings.csv', debug)\n",
    "       tags = readCSV(path +'/tags.csv', debug)\n",
    "    \n",
    "    tags = tags.withColumn('tagl', F.explode(F.split(F.lower(F.col('tag')),'[ \\*\\+\\&\\/\\%\\-\\$\\#\\'\\)\\(\\[\\[\\],.!?;:\\t\\n\"]+')))\\\n",
    "            .drop('tag')\\\n",
    "            .withColumnRenamed('tagl','tag')\n",
    "    if (debug):\n",
    "        print('> movies')\n",
    "        movies.printSchema()\n",
    "        movies.show()\n",
    "        print('> ratings')\n",
    "        ratings.printSchema()\n",
    "        ratings.show()\n",
    "        print('> tags')\n",
    "        tags.printSchema()\n",
    "        tags.show()\n",
    "    return (movies, ratings, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writeCSV / writeParquet (use them to write a data frame to CSV or Parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCSV(df, path): \n",
    "    df.write.csv(path, header=True, mode='overwrite')\n",
    "\n",
    "def writeParquet(df,path):\n",
    "    df.write.parquet(path, mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### createTagListDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTagListDF(csvTagList):\n",
    "    return spark.createDataFrame([ (t,) for t in csvTagList.split(' ')], ['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of functions available only in Spark 2.4 (GCP Spark instances run Spark 2.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType,IntegerType\n",
    "\n",
    "# Define F.array_intersect if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_intersect'):\n",
    "  F.array_intersect = spark.udf\\\n",
    "    .register('array_intersect', \n",
    "       lambda x,y: list(set(x) & set(y)), ArrayType(IntegerType()))\n",
    "\n",
    "# Define F.array_union if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_union'):\n",
    "  F.array_union = spark.udf\\\n",
    "    .register('array_union', \n",
    "       lambda x,y: list(set(x) | set(y)), ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to define \n",
    "\n",
    "__This is the section that will be evaluated.__\n",
    "\n",
    "__Include your code for the various functions required in the assigment below.__\n",
    "\n",
    "__You may include other auxilliary functions required for computation here\n",
    "but NOT test code (see below).__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "    \n",
    "def tfidfTags(tags, debug=False):\n",
    "    \n",
    "    df_f = tags.groupBy('tag', 'movieId')\\\n",
    "            .agg(F.count('userId').alias('f'))\n",
    "    \n",
    "    df_f_max = df_f.groupBy('movieId')\\\n",
    "                .agg(F.max('f').alias('f_max'))\n",
    "    \n",
    "    df_idf = get_idf(data=tags, w='tag', d='movieId', n='n')\n",
    "\n",
    "    df = df_f.join(df_f_max, 'movieId')\\\n",
    "            .withColumn('TF', F.col('f') / F.col('f_max'))\n",
    "    \n",
    "    df = df.join(df_idf, 'tag')\\\n",
    "    \n",
    "    df = df.withColumn('TF_IDF', df.TF*df.IDF)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def recommendByTag(singleTag, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    df = TFIDF_tags.filter(TFIDF_tags.tag == singleTag)\\\n",
    "                    .filter(TFIDF_tags.f_max >= min_fmax)\\\n",
    "                    .join(movies, 'movieId')\\\n",
    "                    .orderBy(['TF_IDF','title'], ascending=[0,1])\\\n",
    "                    .select('movieID', 'title', 'TF_IDF')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def recommendByTags(searchTags, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    searchTagsDF = createTagListDF(searchTags)\n",
    "    if debug:\n",
    "        print('> Search tags DF: ' + searchTags)\n",
    "        searchTagsDF.show()\n",
    "    # TODO\n",
    "    \n",
    "    df_tags = TFIDF_tags.join(searchTagsDF, 'tag', 'inner')\\\n",
    "                    .filter(TFIDF_tags.f_max >= min_fmax)\\\n",
    "\n",
    "    df = df_tags.groupBy('movieId')\\\n",
    "                .agg(F.sum('TF_IDF').alias('SUM_TF_IDF'))\\\n",
    "                .join(movies, 'movieId')\\\n",
    "                .orderBy(['SUM_TF_IDF', 'title'], ascending=[0,1])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jiMovieSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def jiMovieSimilarity(ratings, minRatings=10, debug=False):\n",
    "  # TODO\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendBySimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendBySimilarity(movieId, movies, jiForMovies, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input data set and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gs://bdcc1819/p1/data/tiny3/movies.csv\n",
      "Reading gs://bdcc1819/p1/data/tiny3/ratings.csv\n",
      "Reading gs://bdcc1819/p1/data/tiny3/tags.csv\n",
      "> movies\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|      Jumanji (1995)|\n",
      "|      3|Grumpier Old Men ...|\n",
      "|      4|Waiting to Exhale...|\n",
      "|      5|Father of the Bri...|\n",
      "|      6|         Heat (1995)|\n",
      "|      7|      Sabrina (1995)|\n",
      "|      8| Tom and Huck (1995)|\n",
      "|      9| Sudden Death (1995)|\n",
      "|     10|    GoldenEye (1995)|\n",
      "|     11|American Presiden...|\n",
      "|     12|Dracula: Dead and...|\n",
      "|     13|        Balto (1995)|\n",
      "|     14|        Nixon (1995)|\n",
      "|     15|Cutthroat Island ...|\n",
      "|     16|       Casino (1995)|\n",
      "|     17|Sense and Sensibi...|\n",
      "|     18|   Four Rooms (1995)|\n",
      "|     19|Ace Ventura: When...|\n",
      "|     20|  Money Train (1995)|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> ratings\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+-------+------+------+\n",
      "|movieId|userId|rating|\n",
      "+-------+------+------+\n",
      "|      1|     1|   4.0|\n",
      "|      3|     1|   4.0|\n",
      "|      6|     1|   4.0|\n",
      "|     47|     1|   5.0|\n",
      "|     50|     1|   5.0|\n",
      "|     70|     1|   3.0|\n",
      "|    101|     1|   5.0|\n",
      "|    110|     1|   4.0|\n",
      "|    151|     1|   5.0|\n",
      "|     31|     3|   0.5|\n",
      "|     21|     4|   3.0|\n",
      "|     32|     4|   2.0|\n",
      "|     45|     4|   3.0|\n",
      "|     47|     4|   2.0|\n",
      "|     52|     4|   3.0|\n",
      "|     58|     4|   3.0|\n",
      "|    106|     4|   4.0|\n",
      "|    125|     4|   5.0|\n",
      "|    126|     4|   1.0|\n",
      "|      1|     5|   4.0|\n",
      "+-------+------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> tags\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n",
      "+-------+------+--------------+\n",
      "|movieId|userId|           tag|\n",
      "+-------+------+--------------+\n",
      "|      2|    62|       fantasy|\n",
      "|      2|    62|         magic|\n",
      "|      2|    62|         board|\n",
      "|      2|    62|          game|\n",
      "|      2|    62|         robin|\n",
      "|      2|    62|      williams|\n",
      "|    110|    62|     beautiful|\n",
      "|    110|    62|       scenery|\n",
      "|    110|    62|          epic|\n",
      "|    110|    62|    historical|\n",
      "|    110|    62| inspirational|\n",
      "|    110|    62|      medieval|\n",
      "|    110|    62|           mel|\n",
      "|    110|    62|        gibson|\n",
      "|    110|    62|         oscar|\n",
      "|    110|    62|          best|\n",
      "|    110|    62|cinematography|\n",
      "|    110|    62|              |\n",
      "|    110|    62|       revenge|\n",
      "|    110|    62|         sword|\n",
      "+-------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "bucket = 'gs://bdcc1819'\n",
    "path = '/p1/data/'\n",
    "dataset = 'tiny3'\n",
    "fullPath = bucket + path + dataset\n",
    "\n",
    "(movies, ratings, tags) = \\\n",
    "  loadMovieLensData(fullPath, format='csv', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test code \n",
    "\n",
    "__Include test code below that you may need here.__\n",
    "\n",
    "__The initial contents are only meant as an example.__\n",
    "\n",
    "__This section will NOT be evaluated.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---+-----+------------------+-----------------+-----------------+\n",
      "|        tag|movieId|  f|f_max|                TF|              IDF|           TF_IDF|\n",
      "+-----------+-------+---+-----+------------------+-----------------+-----------------+\n",
      "|       time|     32|  3|    3|               1.0|5.426264754702098|5.426264754702098|\n",
      "|     travel|     32|  3|    3|               1.0|5.426264754702098|5.426264754702098|\n",
      "|      pixar|      1|  2|    2|               1.0|5.426264754702098|5.426264754702098|\n",
      "|       game|      2|  2|    2|               1.0|5.426264754702098|5.426264754702098|\n",
      "|apocalyptic|     32|  2|    3|0.6666666666666666|5.426264754702098|3.617509836468065|\n",
      "|       post|     32|  2|    3|0.6666666666666666|5.426264754702098|3.617509836468065|\n",
      "|      moldy|      3|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|        old|      3|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|  pregnancy|      5|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|      mafia|     16|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|  hollywood|     21|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "| alcoholism|     25|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "| kidnapping|     29|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|       high|     31|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|     school|     31|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|    teacher|     31|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|     animal|     34|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|        for|     34|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|       good|     34|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "|      movie|     34|  1|    1|               1.0|5.426264754702098|5.426264754702098|\n",
      "+-----------+-------+---+-----+------------------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get TF-IDF for tags\n",
    "tfidf = tfidfTags(tags, debug=False)\n",
    "\n",
    "tfidf.cache()\n",
    "tfidf.orderBy(['f','TF_IDF','movieId','tag'],ascending=[0,0,1,1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+\n",
      "|movieID|               title|           TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|     47|Seven (a.k.a. Se7...|3.841302253980942|\n",
      "|     50|Usual Suspects, T...|3.841302253980942|\n",
      "|     32|Twelve Monkeys (a...|1.280434084660314|\n",
      "+-------+--------------------+-----------------+\n",
      "\n",
      "+-------+--------------------+-----------------+\n",
      "|movieID|               title|           TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|     22|      Copycat (1995)|4.426264754702098|\n",
      "|     47|Seven (a.k.a. Se7...|4.426264754702098|\n",
      "+-------+--------------------+-----------------+\n",
      "\n",
      "+-------+--------------------+-----------------+\n",
      "|movieID|               title|           TF_IDF|\n",
      "+-------+--------------------+-----------------+\n",
      "|      5|Father of the Bri...|3.841302253980942|\n",
      "|      7|      Sabrina (1995)|3.841302253980942|\n",
      "|     32|Twelve Monkeys (a...|1.280434084660314|\n",
      "+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommend by tag \n",
    "\n",
    "rm = recommendByTag('twist', tfidf, movies, min_fmax=1)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTag('killer', tfidf, movies, min_fmax=1)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTag('remake', tfidf, movies, min_fmax=1)\n",
    "rm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend by tags\n",
    "\n",
    "# Tests for tiny3\n",
    "rm = recommendByTags('jane austen', tfidf, movies,min_fmax=1)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('remake time twist', tfidf, movies, min_fmax=1)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('robin williams remake', tfidf, movies, min_fmax=1)\n",
    "rm.show()\n",
    "\n",
    "# Tests for tiny 1 (?)\n",
    "#rm = recommendByTags('tom hanks airport', tfidf, movies, numberOfResults=20)\n",
    "#rm.show()\n",
    "\n",
    "#rm = recommendByTags('tom hanks', tfidf, movies, numberOfResults=20)\n",
    "#rm.show()\n",
    "\n",
    "#rm = recommendByTags('hitchcock birds', tfidf, movies, numberOfResults=10)\n",
    "#rm.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiM = jiMovieSimilarity(ratings)\n",
    "\n",
    "#jiM.orderBy(['JI','m1','m2'], ascending=[0,1,1]).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jiM.cache()\n",
    "\n",
    "# Pulp Fiction\n",
    "#sm = recommendBySimilarity(296, movies, jiM)\n",
    "#sm.show()\n",
    "\n",
    "# Fight club\n",
    "#sm = recommendBySimilarity(2959, movies, jiM)\n",
    "#sm.show()\n",
    "    \n",
    "# Shrek\n",
    "#sm = recommendBySimilarity(4306, movies, jiM)\n",
    "#sm.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(*, data, w='w', d='d', n='', debug=False):\n",
    "    \"\"\"Calculates the Inverse Document Frequency (IDF) of a DataFrame\n",
    "\n",
    "    By default, uses the standard usage of IDF, i.e., 'w'\n",
    "    is a word in a document 'd'. If 'n' is set, it also \n",
    "    returns a column containing the number of documents\n",
    "    in which word 'w' appears.\n",
    "\n",
    "    Args:\n",
    "        data: A DataFrame instance.\n",
    "        w: Column name for 'words'\n",
    "        d: Column name for 'documents'\n",
    "        n: Name for the output column containing the\n",
    "            number of documents in which 'w' appears\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with 'w', 'IDF, [n] as columns\n",
    "    \"\"\"\n",
    "    n_w_D = data\\\n",
    "           .groupBy(w)\\\n",
    "           .agg(F.countDistinct(d).alias('n_w_D'))\n",
    "    if debug:\n",
    "        n_w_D.orderBy('n_w_D',ascending=False).show()\n",
    "        \n",
    "    size_of_D = data.select(d).distinct().count()\n",
    "    if debug:\n",
    "        print(\"|D| = %d\" % size_of_D)\n",
    "    \n",
    "    IDF = n_w_D\\\n",
    "            .withColumn('IDF', F.log2(size_of_D / F.col('n_W_D')))\n",
    "    \n",
    "    if n:\n",
    "        IDF = IDF.drop('n_w_D')\n",
    "    else:\n",
    "        IDF = IDF.withColumnRenamed('n_w_D', n)\n",
    "            \n",
    "    return IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made by the teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTF(data, debug=False):\n",
    "    f_wd = data\\\n",
    "       .groupBy('w','d')\\\n",
    "             .agg(F.count('w').alias('f_wd'))\n",
    "    if debug:\n",
    "        f_wd.orderBy('d','w').show()\n",
    "\n",
    "    f_wd_max = f_wd\\\n",
    "             .groupBy('d')\\\n",
    "             .agg(F.max('f_wd').alias('f_wd_max'))\n",
    "    if debug:\n",
    "        f_wd_max.orderBy('d').show()\n",
    "        \n",
    "    TF = f_wd.join(f_wd_max, 'd')\\\n",
    "             .withColumn('TF', F.col('f_wd') / F.col('f_wd_max'))\\\n",
    "             .drop('f_wd','f_wd_max')\n",
    "    return TF\n",
    "\n",
    "def getIDF(data, debug=False):\n",
    "    n_w_D = data\\\n",
    "           .groupBy('w')\\\n",
    "           .agg(F.countDistinct('d').alias('n_w_D'))\n",
    "    if debug:\n",
    "        n_w_D.orderBy('n_w_D',ascending=False).show()\n",
    "        \n",
    "    size_of_D = data.select('d').distinct().count()\n",
    "    if debug:\n",
    "        print(\"|D| = %d\" % size_of_D)\n",
    "    \n",
    "    IDF = n_w_D\\\n",
    "            .withColumn('IDF', F.log2(size_of_D / F.col('n_w_D')))\\\n",
    "            .drop('n_w_D')\n",
    "            \n",
    "    return IDF\n",
    "    \n",
    "def getTF_IDF(data, debug=False):\n",
    "    TF = getTF(data, debug)\n",
    "    if debug:\n",
    "        TF.orderBy(['d','TF'],ascending=[1,0]).show(TF.count())\n",
    "    \n",
    "    IDF = getIDF(data, debug)\n",
    "    if debug:\n",
    "        IDF.orderBy(['IDF','w'], ascending=[0,1]).show(IDF.count())\n",
    "\n",
    "    TF_IDF = TF\\\n",
    "      .join(IDF,'w')\\\n",
    "      .withColumn('TF_IDF',F.col('TF') * F.col('IDF'))\n",
    "        \n",
    "    if debug:\n",
    "        TF_IDF.orderBy(['d','TF_IDF','w'],ascending=[1,0,1]).show(TF_IDF.count())\n",
    "    return TF_IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}