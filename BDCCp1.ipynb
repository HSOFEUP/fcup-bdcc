{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDCC project 1 \n",
    "\n",
    "_[Big Data and Cloud Computing](http://www.dcc.fc.up.pt/~edrdo/aulas/bdcc), DCC/FCUP_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code necessary to run from the command line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    # This block is required to run the program from the command line\n",
    "    # in interface with a single Spark instance\n",
    "    from pyspark import SparkContext\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"BDCCp1\")\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided code - auxilliary functions\n",
    "\n",
    "__You should not need to edit these.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loadMovieLensData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def readCSV(file, debug=False):\n",
    "    if debug:\n",
    "      print('Reading ' + file)\n",
    "    return spark.read.csv(file, inferSchema=True, header=True)\n",
    "\n",
    "def readParquet(file, debug=False): \n",
    "    if debug:\n",
    "       print('Reading ' + file)\n",
    "    return spark.read.parquet(file)\n",
    "\n",
    "def loadMovieLensData(path, format='parquet', debug=False):\n",
    "    if format == 'parquet':\n",
    "       movies = readParquet(path +'/movies.parquet', debug)\n",
    "       ratings = readParquet(path +'/ratings.parquet', debug)\n",
    "       tags = readParquet(path +'/tags.parquet', debug)\n",
    "    else:\n",
    "       movies = readCSV(path +'/movies.csv', debug)\n",
    "       ratings = readCSV(path +'/ratings.csv', debug)\n",
    "       tags = readCSV(path +'/tags.csv', debug)\n",
    "    \n",
    "    tags = tags.withColumn('tagl', F.explode(F.split(F.lower(F.col('tag')),'[ \\*\\+\\&\\/\\%\\-\\$\\#\\'\\)\\(\\[\\[\\],.!?;:\\t\\n\"]+')))\\\n",
    "            .drop('tag')\\\n",
    "            .withColumnRenamed('tagl','tag')\n",
    "    if (debug):\n",
    "        print('> movies')\n",
    "        movies.printSchema()\n",
    "        movies.show()\n",
    "        print('> ratings')\n",
    "        ratings.printSchema()\n",
    "        ratings.show()\n",
    "        print('> tags')\n",
    "        tags.printSchema()\n",
    "        tags.show()\n",
    "    return (movies, ratings, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### writeCSV / writeParquet (use them to write a data frame to CSV or Parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCSV(df, path): \n",
    "    df.write.csv(path, header=True, mode='overwrite')\n",
    "\n",
    "def writeParquet(df,path):\n",
    "    df.write.parquet(path, mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### createTagListDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTagListDF(csvTagList):\n",
    "    return spark.createDataFrame([ (t,) for t in csvTagList.split(' ')], ['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of functions available only in Spark 2.4 (GCP Spark instances run Spark 2.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType,IntegerType\n",
    "\n",
    "# Define F.array_intersect if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_intersect'):\n",
    "  F.array_intersect = spark.udf\\\n",
    "    .register('array_intersect', \n",
    "       lambda x,y: list(set(x) & set(y)), ArrayType(IntegerType()))\n",
    "\n",
    "# Define F.array_union if not defined (Spark version < 2.4)\n",
    "if not hasattr(F,'array_union'):\n",
    "  F.array_union = spark.udf\\\n",
    "    .register('array_union', \n",
    "       lambda x,y: list(set(x) | set(y)), ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to define \n",
    "\n",
    "__This is the section that will be evaluated.__\n",
    "\n",
    "__Include your code for the various functions required in the assigment below.__\n",
    "\n",
    "__You may include other auxilliary functions required for computation here\n",
    "but NOT test code (see below).__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "    \n",
    "def tfidfTags(tags, debug=False):\n",
    "    \n",
    "    df_f = tags.groupBy('tag', 'movieId')\\\n",
    "            .agg(F.count('userId').alias('f'))\n",
    "    \n",
    "    df_f_max = df_f.groupBy('movieId')\\\n",
    "                .agg(F.max('f').alias('f_max'))\n",
    "    \n",
    "    #df_n = tags.groupBy('tag')\\\n",
    "    #        .agg(F.countDistinct('movieId').alias('n'))\n",
    "    \n",
    "    idf = getIDF2(tags, False, False, 'tag', 'movieId')\n",
    "    #return idf\n",
    "    #return df_n\n",
    "\n",
    "    #df = df_f.join(df_n, 'tag')\n",
    "    \n",
    "    df = df_f.join(df_f_max, 'movieId')\\\n",
    "            .withColumn('TF', F.col('f') / F.col('f_max'))\n",
    "    \n",
    "    df = df.join(idf, 'tag')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def recommendByTag(singleTag, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "    \n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendByTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def recommendByTags(searchTags, TFIDF_tags, movies, min_fmax=10, numberOfResults=10, debug=False):\n",
    "    searchTagsDF = createTagListDF(searchTags)\n",
    "    if debug:\n",
    "        print('> Search tags DF: ' + searchTags)\n",
    "        searchTagsDF.show()\n",
    "    # TODO\n",
    "        \n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jiMovieSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def jiMovieSimilarity(ratings, minRatings=10, debug=False):\n",
    "  # TODO\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recommendBySimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendBySimilarity(movieId, movies, jiForMovies, numberOfResults=10, debug=False):\n",
    "    # TODO\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input data set and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gs://bdcc1819/p1/data/tiny3/movies.csv\n",
      "Reading gs://bdcc1819/p1/data/tiny3/ratings.csv\n",
      "Reading gs://bdcc1819/p1/data/tiny3/tags.csv\n",
      "> movies\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|      Jumanji (1995)|\n",
      "|      3|Grumpier Old Men ...|\n",
      "|      4|Waiting to Exhale...|\n",
      "|      5|Father of the Bri...|\n",
      "|      6|         Heat (1995)|\n",
      "|      7|      Sabrina (1995)|\n",
      "|      8| Tom and Huck (1995)|\n",
      "|      9| Sudden Death (1995)|\n",
      "|     10|    GoldenEye (1995)|\n",
      "|     11|American Presiden...|\n",
      "|     12|Dracula: Dead and...|\n",
      "|     13|        Balto (1995)|\n",
      "|     14|        Nixon (1995)|\n",
      "|     15|Cutthroat Island ...|\n",
      "|     16|       Casino (1995)|\n",
      "|     17|Sense and Sensibi...|\n",
      "|     18|   Four Rooms (1995)|\n",
      "|     19|Ace Ventura: When...|\n",
      "|     20|  Money Train (1995)|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> ratings\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+-------+------+------+\n",
      "|movieId|userId|rating|\n",
      "+-------+------+------+\n",
      "|      1|     1|   4.0|\n",
      "|      3|     1|   4.0|\n",
      "|      6|     1|   4.0|\n",
      "|     47|     1|   5.0|\n",
      "|     50|     1|   5.0|\n",
      "|     70|     1|   3.0|\n",
      "|    101|     1|   5.0|\n",
      "|    110|     1|   4.0|\n",
      "|    151|     1|   5.0|\n",
      "|     31|     3|   0.5|\n",
      "|     21|     4|   3.0|\n",
      "|     32|     4|   2.0|\n",
      "|     45|     4|   3.0|\n",
      "|     47|     4|   2.0|\n",
      "|     52|     4|   3.0|\n",
      "|     58|     4|   3.0|\n",
      "|    106|     4|   4.0|\n",
      "|    125|     4|   5.0|\n",
      "|    126|     4|   1.0|\n",
      "|      1|     5|   4.0|\n",
      "+-------+------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "> tags\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n",
      "+-------+------+--------------+\n",
      "|movieId|userId|           tag|\n",
      "+-------+------+--------------+\n",
      "|      2|    62|       fantasy|\n",
      "|      2|    62|         magic|\n",
      "|      2|    62|         board|\n",
      "|      2|    62|          game|\n",
      "|      2|    62|         robin|\n",
      "|      2|    62|      williams|\n",
      "|    110|    62|     beautiful|\n",
      "|    110|    62|       scenery|\n",
      "|    110|    62|          epic|\n",
      "|    110|    62|    historical|\n",
      "|    110|    62| inspirational|\n",
      "|    110|    62|      medieval|\n",
      "|    110|    62|           mel|\n",
      "|    110|    62|        gibson|\n",
      "|    110|    62|         oscar|\n",
      "|    110|    62|          best|\n",
      "|    110|    62|cinematography|\n",
      "|    110|    62|              |\n",
      "|    110|    62|       revenge|\n",
      "|    110|    62|         sword|\n",
      "+-------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "bucket = 'gs://bdcc1819'\n",
    "path = '/p1/data/'\n",
    "dataset = 'tiny3'\n",
    "fullPath = bucket + path + dataset\n",
    "\n",
    "(movies, ratings, tags) = \\\n",
    "  loadMovieLensData(fullPath, format='csv', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test code \n",
    "\n",
    "__Include test code below that you may need here.__\n",
    "\n",
    "__The initial contents are only meant as an example.__\n",
    "\n",
    "__This section will NOT be evaluated.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---+-----+------------------+-----+-----------------+\n",
      "|        tag|movieId|  f|f_max|                TF|n_w_D|              IDF|\n",
      "+-----------+-------+---+-----+------------------+-----+-----------------+\n",
      "|         in|     28|  1|    1|               1.0|    2|4.426264754702098|\n",
      "|       epic|    110|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|       pitt|     32|  1|    3|0.3333333333333333|    1|5.426264754702098|\n",
      "|       hyde|     92|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|       game|      2|  2|    2|               1.0|    1|5.426264754702098|\n",
      "|     remake|     32|  1|    3|0.3333333333333333|    3|3.841302253980942|\n",
      "|apocalyptic|     32|  2|    3|0.6666666666666666|    1|5.426264754702098|\n",
      "|       time|     32|  3|    3|               1.0|    1|5.426264754702098|\n",
      "|       adam|    104|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|  beautiful|    110|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|         in|     40|  1|    1|               1.0|    2|4.426264754702098|\n",
      "|        tag|    104|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|      moldy|      3|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|     tricky|     50|  1|    1|               1.0|    1|5.426264754702098|\n",
      "| alcoholism|     25|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|   wahlberg|    147|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|       emma|     39|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|     africa|     40|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|      movie|     34|  1|    1|               1.0|    1|5.426264754702098|\n",
      "|      mafia|     16|  1|    1|               1.0|    1|5.426264754702098|\n",
      "+-----------+-------+---+-----+------------------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get TF-IDF for tags\n",
    "tfidf = tfidfTags(tags, debug=False)\n",
    "tfidf.show()\n",
    "#tfidf.cache()\n",
    "#tfidf.orderBy('TF',ascending=True).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend by tag \n",
    "\n",
    "rm = recommendByTag('cartoon', tfidf, movies)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTag('cartoon', tfidf, movies, min_fmax=1)\n",
    "rm.show()\n",
    "\n",
    "\n",
    "rm = recommendByTag('cruise', tfidf, movies)\n",
    "rm.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "rm = recommendByTags('tom hanks cruise', tfidf, movies, numberOfResults=20)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('tom hanks airport', tfidf, movies, numberOfResults=20)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('tom hanks', tfidf, movies, numberOfResults=20)\n",
    "rm.show()\n",
    "\n",
    "rm = recommendByTags('hitchcock birds', tfidf, movies, numberOfResults=10)\n",
    "rm.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jiM = jiMovieSimilarity(ratings)\n",
    "\n",
    "#jiM.orderBy(['JI','m1','m2'], ascending=[0,1,1]).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jiM.cache()\n",
    "\n",
    "# Pulp Fiction\n",
    "#sm = recommendBySimilarity(296, movies, jiM)\n",
    "#sm.show()\n",
    "\n",
    "# Fight club\n",
    "#sm = recommendBySimilarity(2959, movies, jiM)\n",
    "#sm.show()\n",
    "    \n",
    "# Shrek\n",
    "#sm = recommendBySimilarity(4306, movies, jiM)\n",
    "#sm.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTF(data, debug=False):\n",
    "    f_wd = data\\\n",
    "       .groupBy('w','d')\\\n",
    "             .agg(F.count('w').alias('f_wd'))\n",
    "    if debug:\n",
    "        f_wd.orderBy('d','w').show()\n",
    "\n",
    "    f_wd_max = f_wd\\\n",
    "             .groupBy('d')\\\n",
    "             .agg(F.max('f_wd').alias('f_wd_max'))\n",
    "    if debug:\n",
    "        f_wd_max.orderBy('d').show()\n",
    "        \n",
    "    TF = f_wd.join(f_wd_max, 'd')\\\n",
    "             .withColumn('TF', F.col('f_wd') / F.col('f_wd_max'))\\\n",
    "             .drop('f_wd','f_wd_max')\n",
    "    return TF\n",
    "\n",
    "def getIDF(data, debug=False):\n",
    "    n_w_D = data\\\n",
    "           .groupBy('w')\\\n",
    "           .agg(F.countDistinct('d').alias('n_w_D'))\n",
    "    if debug:\n",
    "        n_w_D.orderBy('n_w_D',ascending=False).show()\n",
    "        \n",
    "    size_of_D = data.select('d').distinct().count()\n",
    "    if debug:\n",
    "        print(\"|D| = %d\" % size_of_D)\n",
    "    \n",
    "    IDF = n_w_D\\\n",
    "            .withColumn('IDF', F.log2(size_of_D / F.col('n_w_D')))\\\n",
    "            .drop('n_w_D')\n",
    "            \n",
    "    return IDF\n",
    "\n",
    "# By default, uses the standard usage of IDF -> 'w' is a word in a document 'd'\n",
    "# Set w or d to use different column names\n",
    "def getIDF2(data, debug=False, drop_n=True, w='w', d='d', n='n_w_D'):\n",
    "    n_w_D = data\\\n",
    "           .groupBy(w)\\\n",
    "           .agg(F.countDistinct(d).alias(n))\n",
    "    if debug:\n",
    "        n_w_D.orderBy('n_w_D',ascending=False).show()\n",
    "        \n",
    "    size_of_D = data.select(d).distinct().count()\n",
    "    if debug:\n",
    "        print(\"|D| = %d\" % size_of_D)\n",
    "    \n",
    "    IDF = n_w_D\\\n",
    "            .withColumn('IDF', F.log2(size_of_D / F.col(n)))\n",
    "    \n",
    "    if drop_n:\n",
    "        IDF = IDF.drop('n_w_D')\n",
    "            \n",
    "    return IDF\n",
    "    \n",
    "def getTF_IDF(data, debug=False):\n",
    "    TF = getTF(data, debug)\n",
    "    if debug:\n",
    "        TF.orderBy(['d','TF'],ascending=[1,0]).show(TF.count())\n",
    "    \n",
    "    IDF = getIDF(data, debug)\n",
    "    if debug:\n",
    "        IDF.orderBy(['IDF','w'], ascending=[0,1]).show(IDF.count())\n",
    "\n",
    "    TF_IDF = TF\\\n",
    "      .join(IDF,'w')\\\n",
    "      .withColumn('TF_IDF',F.col('TF') * F.col('IDF'))\n",
    "        \n",
    "    if debug:\n",
    "        TF_IDF.orderBy(['d','TF_IDF','w'],ascending=[1,0,1]).show(TF_IDF.count())\n",
    "    return TF_IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}